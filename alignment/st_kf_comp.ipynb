{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03543cac-c9af-4aa1-9e56-d71de28c9baa",
   "metadata": {},
   "source": [
    "# ST-KF Comparison\n",
    "We want to use the Kalman Filter (KF) instead of the Seed Tracker (ST) to determine tracks within HPS. In order to fully adopt KF, we also need to make sure that the alignment procedure with General Broken Lines (GBL) and Millepede (MP) can still function. This document is meant to compare KF-based alignment to ST-based alignment so that we can debug the KF-based one.\n",
    "\n",
    "MP returns delta = supposed - reality => reality = supposed - delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef83fa0c-09d3-4ab1-aa05-775506d197ea",
   "metadata": {},
   "source": [
    "## Layer 1 Top, $\\Delta y = + 100\\mu$m\n",
    "The first comparison is a very simple manipulation. We shift layer 1 in the top box up by 100 microns (specifically, the whole module -- paramter 11161)\n",
    "\n",
    "Both ST and KF went successfully aligned. Below I've listed the MP-deduced alignment parameter in mm. I ran MP only allowing the parameter that I had changed to float.\n",
    "\n",
    "**ST**:\n",
    "1. 0.090370 (from 0.1 offset)\n",
    "2. 0.010166 (from 0.00963 offset)\n",
    "3. 0.000733 (from -0.000536 offset)\n",
    "4. 0.000026 (from -0.001269 offset)\n",
    "5. 0.000002 (from -0.001271 offset)\n",
    "\n",
    "**KF**:\n",
    "1. 0.069387 (from 0.1 offset)\n",
    "2. 0.021440 (from 0.030613 offset)\n",
    "3. 0.006703 (from 0.009173 offset)\n",
    "4. 0.002120 (from 0.002470 offset)\n",
    "5. 0.000644 (from 0.000350 offset)\n",
    "6. 0.000211 (from -0.000294 offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62dac2b8-08f0-4afa-848f-9de80776385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _differ import Differ\n",
    "d = Differ('L1t $\\Delta y = +100\\mu$m',\n",
    "           ('kf/HPS_2019_L1ty100um_iter0/no_constraints_gblplots.root','KF iter0', dict(color='tab:blue')),\n",
    "           ('st/HPS_2019_L1ty100um_iter0/no_constraints_gblplots.root','ST iter0', dict(color='tab:orange')),\n",
    "#           ('kf/HPS_2019_L1ty100um_iter1/no_constraints_gblplots.root','KF iter1', dict(color='tab:green')),\n",
    "#           ('st/HPS_2019_L1ty100um_iter1/no_constraints_gblplots.root','ST iter1', dict(color='tab:red')),\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3046bbb-75a5-4352-9616-0dec80e7ccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplhep\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(mplhep.style.ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65fbe2e8-d8f1-4f6a-9155-0bff467c2fae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 792x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d.plot1d('trk_params/nHits_top','N Hits Top',ylabel='Count',yscale='linear',legend_kw=dict(loc='upper left'), out_dir=os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a0cbd71-635b-4eb1-ba63-89ce7e31966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "def core_mean(vals, weights) :\n",
    "    \"\"\"Iteratively find the core of the distribution by removing bins outside 2 stdd away\"\"\"\n",
    "    # normalize weights first\n",
    "    weights = weights/weights.sum()\n",
    "    sl = np.full((len(weights)), True)\n",
    "    for i in range(5) :\n",
    "        # make the selection\n",
    "        vals = vals[sl]\n",
    "        weights = weights[sl]\n",
    "        # calculate the mean/std-dev\n",
    "        mean = (weights*vals).sum()\n",
    "        stdd = math.sqrt((weights*(vals-mean)**2).sum())\n",
    "        # determine range of acceptable values\n",
    "        low = mean - 5*stdd\n",
    "        hi  = mean + 5*stdd\n",
    "        # define new slice\n",
    "        sl = (vals > low) & (vals < hi)\n",
    "    \n",
    "    return mean, stdd\n",
    "\n",
    "def manual_cut(low, high) :\n",
    "    \"\"\"Manually decide what values to cut on\"\"\"\n",
    "    def calculator(vals, weights) :\n",
    "        sl = (vals > low) & (vals < high)\n",
    "        vals = vals[sl]\n",
    "        weights = weights[sl]\n",
    "        mean = (weights*vals).sum()/(weights.sum())\n",
    "        stdd = math.sqrt((weights*(vals-mean)**2).sum()/(weights.sum()))\n",
    "        return mean, stdd\n",
    "    return calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e69f2ce-e5ff-4c36-bdc8-a11578fca02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 792x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "sensors = [\n",
    "    ('L1b Axial', 'res/uresidual_GBL_module_L1b_halfmodule_axial_sensor0', True),\n",
    "    ('L1b Stereo', 'res/uresidual_GBL_module_L1b_halfmodule_stereo_sensor0', True),\n",
    "    ('L1t Axial', 'res/uresidual_GBL_module_L1t_halfmodule_axial_sensor0', True),\n",
    "    ('L1t Stereo', 'res/uresidual_GBL_module_L1t_halfmodule_stereo_sensor0', True),\n",
    "]\n",
    "for name, hist, im in sensors :\n",
    "    d.plot1d(hist, f'Unbiased Residual {name} [mm]', ylabel='Count', include_mean = im, \n",
    "             density = True, yscale='linear', legend_kw = dict(loc='upper left'), draw_mean = True, out_dir=os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c68877d8-d4fe-4e00-a06c-51d3110c6a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find mean of distribution core\n",
    "#   iterative gaussian fit\n",
    "import uproot\n",
    "h = uproot.open('kf/HPS_2019_L1ty100um_iter0/no_constraints_gblplots.root')['res/uresidual_GBL_module_L1t_halfmodule_axial_sensor0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3fc77543-728f-4a5a-8758-b01fa7ecb16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.047245283018867934 0.031205715826775626\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "mean = (h.values()*h.axis('x').centers()).sum()/(h.values().sum())\n",
    "std  = math.sqrt((h.values()*(h.axis('x').centers() - mean)**2).sum()/(h.values().sum()))\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dca143d-c37b-47cb-bf27-89c1a042eb9a",
   "metadata": {},
   "source": [
    "## Layer 2 Top, Axial +50 um, Stereo $\\Delta y = -50\\mu$m\n",
    "\n",
    "PF: -35um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c45fac-c420-4d05-8f21-d223eeaf2d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
